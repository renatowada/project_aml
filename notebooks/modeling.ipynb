{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e65aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18792ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/01_raw/metrics_df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5638b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            in_degree  out_degree   total_in  total_out  avg_retention_hours  \\\n",
      "account_id                                                                     \n",
      "acc014958           4           2   15828.16    2693.18           159.031944   \n",
      "acc032333           2           2    3246.27    3525.78          -368.813750   \n",
      "acc021462           0           2       0.00   31889.71          9999.000000   \n",
      "acc002326           4           4   83173.59   72816.52           -48.398333   \n",
      "acc004656          23           1  438247.08    1438.85          -908.078333   \n",
      "\n",
      "               ratio  is_suspect  is_fraud    role  \n",
      "account_id                                          \n",
      "acc014958   0.170151           0         0  Honest  \n",
      "acc032333   1.086099           0         0  Honest  \n",
      "acc021462   0.000000           0         0  Honest  \n",
      "acc002326   0.875476           0         1    Mule  \n",
      "acc004656   0.003283           0         1    Boss  \n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(\"../data/01_raw/accounts_labels.csv\").set_index('account_id')\n",
    "\n",
    "metrics_df = df.join(labels_df, how='inner')\n",
    "\n",
    "print(metrics_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf42306",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = metrics_df[['in_degree', 'out_degree', 'total_in', 'ratio', 'avg_retention_hours']]\n",
    "\n",
    "y = metrics_df['is_fraud'] # Em uma situação real essa informação não estaria disponível, mas já que eu tenho..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ba05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de treino == 70%\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2c4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de Validação == 15%\n",
    "# Conjunto de Teste == 15%\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6379c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9408948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Métricas de Regressão Logística---\n",
      "AUC-ROC Score: 0.98\n",
      "Recall Score: 0.92\n",
      "Precision Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Regressão Logística\n",
    "model_lr = LogisticRegression(max_iter=10000, class_weight='balanced', random_state=12345)\n",
    "model_lr.fit(X_train, y_train)\n",
    "probs_lr = model_lr.predict_proba(X_val)[:, 1] # Para auc-roc\n",
    "preds_lr = model_lr.predict(X_val)             # Para precision e recall\n",
    "auc_lr = roc_auc_score(y_val, probs_lr)\n",
    "recall_lr = recall_score(y_val, preds_lr)\n",
    "precision_lr = precision_score(y_val, preds_lr)\n",
    "\n",
    "print('---Métricas de Regressão Logística---')\n",
    "print(f\"AUC-ROC Score: {auc_lr:.2f}\")\n",
    "print(f\"Recall Score: {recall_lr:.2f}\")\n",
    "print(f\"Precision Score: {precision_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a57925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Métricas de Random Forest---\n",
      "AUC-ROC Score: 0.97\n",
      "Recall Score: 0.88\n",
      "Precision Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "model_rf = RandomForestClassifier(class_weight='balanced', random_state=12345)\n",
    "model_rf.fit(X_train, y_train)\n",
    "probs_rf = model_rf.predict_proba(X_val)[:, 1]\n",
    "preds_rf = model_rf.predict(X_val)\n",
    "auc_rf = roc_auc_score(y_val, probs_rf)\n",
    "recall_rf = recall_score(y_val, preds_rf)\n",
    "precision_rf = precision_score(y_val, preds_rf)\n",
    "\n",
    "print('---Métricas de Random Forest---')\n",
    "print(f\"AUC-ROC Score: {auc_rf:.2f}\")\n",
    "print(f\"Recall Score: {recall_rf:.2f}\")\n",
    "print(f\"Precision Score: {precision_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa012f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Métricas de XGB---\n",
      "AUC-ROC Score: 0.98\n",
      "Recall Score: 0.88\n",
      "Precision Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "model_xgb = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=12345, \n",
    "    learning_rate=0.05,\n",
    "    reg_alpha=1.0, # diminui peso de features muito fortes\n",
    "    reg_lambda=1.0\n",
    ")\n",
    "model_xgb.fit(X_train, y_train)\n",
    "probs_xgb = model_xgb.predict_proba(X_val)[:, 1]\n",
    "preds_xgb = model_xgb.predict(X_val)\n",
    "auc_xgb = roc_auc_score(y_val, probs_xgb)\n",
    "recall_xgb = recall_score(y_val, preds_xgb)\n",
    "precision_xgb = precision_score(y_val, preds_xgb)\n",
    "\n",
    "print('---Métricas de XGB---')\n",
    "print(f\"AUC-ROC Score: {auc_xgb:.2f}\")\n",
    "print(f\"Recall Score: {recall_xgb:.2f}\")\n",
    "print(f\"Precision Score: {precision_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2fbe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Métricas de Teste para XGB---\n",
      "AUC-ROC Score: 0.99\n",
      "Recall Score: 0.92\n",
      "Precision Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "probs_test = model_xgb.predict_proba(X_test)[:, 1]\n",
    "preds_test = model_xgb.predict(X_test)\n",
    "\n",
    "auc_test = roc_auc_score(y_test, probs_test)\n",
    "recall_test = recall_score(y_test, preds_test)\n",
    "precision_test = precision_score(y_test, preds_test)\n",
    "\n",
    "print('---Métricas de Teste para XGB---')\n",
    "print(f\"AUC-ROC Score: {auc_test:.2f}\")\n",
    "print(f\"Recall Score: {recall_test:.2f}\")\n",
    "print(f\"Precision Score: {precision_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edaa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo atualizado com as colunas necessárias!\n"
     ]
    }
   ],
   "source": [
    "# Exportando em csv para Visualização e Power BI\n",
    "best_model = model_xgb\n",
    "\n",
    "all_probs = best_model.predict_proba(X)[:, 1]\n",
    "all_preds = best_model.predict(X)\n",
    "\n",
    "df_export = X.copy()\n",
    "df_export['probabilidade_fraude'] = all_probs\n",
    "df_export['predicao_classe'] = all_preds\n",
    "df_export['is_fraud_real'] = y\n",
    "\n",
    "cols_extras = ['role']\n",
    "df_export = df_export.join(metrics_df[cols_extras], how='left')\n",
    "\n",
    "df_export.to_csv('../data/01_raw/resultados_finais_modelagem.csv', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
